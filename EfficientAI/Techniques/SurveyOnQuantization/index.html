
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Eric025">
      
      
      
        <link rel="prev" href="../../MIT6.5940/Pruning/">
      
      
        <link rel="next" href="../../Parallelism/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>量化学习笔记：从 GPTQ 到 ZIPCache - Eric025's Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+Simplified+Chinese:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans Simplified Chinese";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../styles/global.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#gptq-zipcache" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Eric025&#39;s Blog" class="md-header__button md-logo" aria-label="Eric025's Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Eric025's Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              量化学习笔记：从 GPTQ 到 ZIPCache
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/erix025/erix025.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    erix025.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Eric025 的个人博客

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../MIT6.5940/Introduction/" class="md-tabs__link">
          
  
  
  Efficient AI

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Eric025&#39;s Blog" class="md-nav__button md-logo" aria-label="Eric025's Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Eric025's Blog
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/erix025/erix025.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    erix025.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Eric025 的个人博客
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Efficient AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Efficient AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    MIT 6.5940
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            MIT 6.5940
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../MIT6.5940/Introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    课程介绍
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../MIT6.5940/Pruning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pruning
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Efficient Techniques
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Efficient Techniques
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    量化学习笔记：从 GPTQ 到 ZIPCache
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    量化学习笔记：从 GPTQ 到 ZIPCache
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      什么是量化？
    </span>
  </a>
  
    <nav class="md-nav" aria-label="什么是量化？">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      数据类型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      基本方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="基本方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means-based-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      K-Means-based Quantization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Quantization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qat-ptq" class="md-nav__link">
    <span class="md-ellipsis">
      QAT 与 PTQ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QAT 与 PTQ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qat" class="md-nav__link">
    <span class="md-ellipsis">
      QAT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ptq" class="md-nav__link">
    <span class="md-ellipsis">
      PTQ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gptq-pruning-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ: 从 Pruning 到 Quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPTQ: 从 Pruning 到 Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#obsobcobqgptq" class="md-nav__link">
    <span class="md-ellipsis">
      OBS、OBC、OBQ：GPTQ 的前世今生
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OBS、OBC、OBQ：GPTQ 的前世今生">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#obs" class="md-nav__link">
    <span class="md-ellipsis">
      OBS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#obc-obq" class="md-nav__link">
    <span class="md-ellipsis">
      OBC &amp; OBQ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptq" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptq_1" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ 代码实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptq_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 GPTQ 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#awq" class="md-nav__link">
    <span class="md-ellipsis">
      AWQ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AWQ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#awq_1" class="md-nav__link">
    <span class="md-ellipsis">
      AWQ 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#awq_2" class="md-nav__link">
    <span class="md-ellipsis">
      AWQ 代码实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#awq_3" class="md-nav__link">
    <span class="md-ellipsis">
      对 AWQ 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qlora" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QLoRA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lora-low-rank-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA: low-rank fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora_1" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 QLoRA 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qllm" class="md-nav__link">
    <span class="md-ellipsis">
      QLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qllm_1" class="md-nav__link">
    <span class="md-ellipsis">
      QLLM 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qllm_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 QLLM 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#zipcache" class="md-nav__link">
    <span class="md-ellipsis">
      ZipCache
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZipCache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zipcache_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZipCache 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zipcache_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 ZipCache 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      下一步工作
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Parallelism/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    大模型并行策略
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Basis of Diffusion Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Basis of Diffusion Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../basis_of_diffusion/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    基础知识
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      什么是量化？
    </span>
  </a>
  
    <nav class="md-nav" aria-label="什么是量化？">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      基本概念
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      数据类型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      基本方法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="基本方法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means-based-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      K-Means-based Quantization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Quantization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qat-ptq" class="md-nav__link">
    <span class="md-ellipsis">
      QAT 与 PTQ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QAT 与 PTQ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qat" class="md-nav__link">
    <span class="md-ellipsis">
      QAT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ptq" class="md-nav__link">
    <span class="md-ellipsis">
      PTQ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gptq-pruning-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ: 从 Pruning 到 Quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPTQ: 从 Pruning 到 Quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#obsobcobqgptq" class="md-nav__link">
    <span class="md-ellipsis">
      OBS、OBC、OBQ：GPTQ 的前世今生
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OBS、OBC、OBQ：GPTQ 的前世今生">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#obs" class="md-nav__link">
    <span class="md-ellipsis">
      OBS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#obc-obq" class="md-nav__link">
    <span class="md-ellipsis">
      OBC &amp; OBQ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptq" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptq_1" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ 代码实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptq_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 GPTQ 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#awq" class="md-nav__link">
    <span class="md-ellipsis">
      AWQ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AWQ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#awq_1" class="md-nav__link">
    <span class="md-ellipsis">
      AWQ 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#awq_2" class="md-nav__link">
    <span class="md-ellipsis">
      AWQ 代码实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#awq_3" class="md-nav__link">
    <span class="md-ellipsis">
      对 AWQ 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qlora" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QLoRA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lora-low-rank-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      LoRA: low-rank fine-tuning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora_1" class="md-nav__link">
    <span class="md-ellipsis">
      QLoRA 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qlora_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 QLoRA 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#qllm" class="md-nav__link">
    <span class="md-ellipsis">
      QLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="QLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qllm_1" class="md-nav__link">
    <span class="md-ellipsis">
      QLLM 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qllm_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 QLLM 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#zipcache" class="md-nav__link">
    <span class="md-ellipsis">
      ZipCache
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZipCache">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zipcache_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZipCache 的核心想法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zipcache_2" class="md-nav__link">
    <span class="md-ellipsis">
      对 ZipCache 的一些思考
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      下一步工作
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="gptq-zipcache">量化学习笔记：从 GPTQ 到 ZIPCache</h1>
<div style="margin-top: -30px; font-size: 0.75em; opacity: 0.7;">
<p><span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10h-2a8 8 0 0 1-8 8 8 8 0 0 1-8-8 8 8 0 0 1 8-8zm6.78 1a.7.7 0 0 0-.48.2l-1.22 1.21 2.5 2.5L20.8 5.7c.26-.26.26-.7 0-.95L19.25 3.2c-.13-.13-.3-.2-.47-.2m-2.41 2.12L9 12.5V15h2.5l7.37-7.38z"/></svg></span> 约 3907 个字 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M392.8 1.2c-17-4.9-34.7 5-39.6 22l-128 448c-4.9 17 5 34.7 22 39.6s34.7-5 39.6-22l128-448c4.9-17-5-34.7-22-39.6m80.6 120.1c-12.5 12.5-12.5 32.8 0 45.3l89.3 89.4-89.4 89.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l112-112c12.5-12.5 12.5-32.8 0-45.3l-112-112c-12.5-12.5-32.8-12.5-45.3 0zm-306.7 0c-12.5-12.5-32.8-12.5-45.3 0l-112 112c-12.5 12.5-12.5 32.8 0 45.3l112 112c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L77.3 256l89.4-89.4c12.5-12.5 12.5-32.8 0-45.3"/></svg></span> 46 行代码 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 17H7V3h14m0-2H7a2 2 0 0 0-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2M3 5H1v16a2 2 0 0 0 2 2h16v-2H3m12.96-10.71-2.75 3.54-1.96-2.36L8.5 15h11z"/></svg></span> 10 张图片 <span class="twemoji"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20c4.42 0 8-3.58 8-8s-3.58-8-8-8-8 3.58-8 8 3.58 8 8 8m0-18c5.5 0 10 4.5 10 10s-4.5 10-10 10C6.47 22 2 17.5 2 12S6.5 2 12 2m.5 11H11V7h1.5v4.26l3.7-2.13.75 1.3z"/></svg></span> 预计阅读时间 14 分钟</p>
</div>
<p>这篇笔记将从量化的概念开始，到介绍 GPTQ、AWQ、QLoRA、QLLM 和 ZIPCache 等量化技术，呈现 Overview of Quantization。</p>
<h2 id="_1">什么是量化？</h2>
<blockquote>
<p>此处参考了 MIT 6.5940 的课程内容。</p>
</blockquote>
<h3 id="_2">基本概念</h3>
<p>量化 (Quantization) 的核心想法是通过降低数值存储和计算的精度来降低访存 (Memory Access) 和计算 (Computation) 的开销。</p>
<p>我认为量化目前 work 的核心在于一个基本假设：Parameters are not fully trained. 基于这个假设，才能够推出目前的精度表示是存在浪费的，从而量化能够 improve efficiency while maintaining the performance。这和 Scaling Laws for Precision (Kumar, 2024) 的想法是一致的，即当数据量到达一定程度，参数被充分训练后，低精度量化会带来显著的性能下降。</p>
<h3 id="_3">数据类型</h3>
<p>这部分介绍一些基本的量化数据类型，需要查阅的时候可以参考。</p>
<ul>
<li>FP64: 深度学习要什么 FP64.jpg</li>
<li>FP32: float, 1+8+23</li>
<li>FP16: half, 1+5+10</li>
<li>BP16: 1+8+7, 深度学习要什么精度.jpg</li>
<li>FP8: 分为 E4M3 和 E5M2 两种，分别是 1+4+3 和 1+5+2</li>
<li>FP4: 1+2+1, Blackwell Architecture 添加了原生支持（对其实用性深表怀疑）</li>
<li>NF4: QLoRA 提出，数值的分布是正态分布而非均匀分布，详见 QLoRA 阅读笔记部分</li>
<li>INT8, INT4: 1+7/3, 整数表示</li>
</ul>
<h3 id="_4">基本方法</h3>
<h4 id="k-means-based-quantization">K-Means-based Quantization</h4>
<p>核心思路：Weight -&gt; K-mean clusters -&gt; index + codebook = QWeight</p>
<p><img alt="K-Means-based Quantization 示意图" src="../SurveyOnQuantization.assets/kmeans_quant.png" /></p>
<p>低精度存储 index，高精度存储 codebook</p>
<p>但现在这种方法不是主流：</p>
<ol>
<li>K-means 难以处理 outlier 的问题</li>
<li>需要高精度存储 codebook，compress rate 不高</li>
<li>只减小了访存量，计算时引入额外的 dequant overhead，计算性能并没有提升</li>
</ol>
<h4 id="linear-quantization">Linear Quantization</h4>
<p>目前的主流方法。</p>
<p>核心思路：<span class="arithmatex">\(\text{weight} = (\text{qweight} - \text{zero}) \times \text{scale}\)</span></p>
<details class="量化参数的计算">
<summary>量化参数的计算</summary>
<div class="arithmatex">\[
\\
\begin{aligned}
r_{\text{max}} = S(q_{\text{max}} - Z)\\
r_{\text{min}} = S(q_{\text{min}} - Z)
\end{aligned}
\]</div>
<p>由此推导出 <span class="arithmatex">\(S, Z\)</span> 的计算公式：</p>
<div class="arithmatex">\[
S = \frac {r_{\text{max}} - r_{\text{min}}} {q_{\text{max}} - q_{\text{min}}}
\]</div>
</details>
<p>这个思路支持多种量化方案：</p>
<ul>
<li>Weight Only Quantization: 和 K-Means-based 类似，引入额外 overhead from dequantization，适用于 memory bound 的 decoding 阶段。</li>
<li>Weight and Activation Quantization: 可以充分利用硬件特性编写 customized kernel 直接进行低精度运算得到结果，既减小访存开销也减小计算开销。</li>
</ul>
<h3 id="qat-ptq">QAT 与 PTQ</h3>
<p>目前主流在 LLM 中的量化应用主要分两种：QAT (Quantization-Aware Training) 和 PTQ (Post-Training Quantization)。</p>
<h4 id="qat">QAT</h4>
<p>在训练阶段就采用量化，将量化后权重的 rounding error 在训练阶段就纳入考虑，从而减少量化带来的 performance degradation。</p>
<p><img alt="QAT" src="../SurveyOnQuantization.assets/qat.png" /></p>
<h4 id="ptq">PTQ</h4>
<p>通过量化训练好的权重来提升模型推理性能，因为不需要重新训练模型而成本较低，广泛使用。</p>
<p>下面介绍一些量化的粒度（即将若干权重进行 grouping，计算量化参数）。粒度越小量化损失越低，但存储量化参数的开销越大。</p>
<ul>
<li>Per-Tensor Quantization</li>
<li>Per-Channel Quantization</li>
<li>Group Quantization</li>
<li>Multi-level Quantization: <span class="arithmatex">\(r = (q-z) \cdot s_0 \cdot s_1 \cdots\)</span>. level 越低，粒度越低，量化参数精度越低。是 Low Compression Rate 和 High Flexibility 的折中。</li>
</ul>
<h2 id="gptq-pruning-quantization">GPTQ: 从 Pruning 到 Quantization</h2>
<h3 id="obsobcobqgptq">OBS、OBC、OBQ：GPTQ 的前世今生</h3>
<details class="quote">
<summary>Quote</summary>
<ul>
<li>B. Hassibi, D. G. Stork, and G. J. Wolff, “Optimal Brain Surgeon and general network pruning,” in IEEE International Conference on Neural Networks, Mar. 1993, pp. 293–299 vol.1. doi: 10.1109/ICNN.1993.298572.</li>
<li>E. Frantar, S. P. Singh, and D. Alistarh, “Optimal Brain Compression: A Framework for Accurate Post-Training Quantization and Pruning,” 2022, arXiv. doi: 10.48550/ARXIV.2208.11580.</li>
</ul>
</details>
<h4 id="obs">OBS</h4>
<p>OBS 本来是用于 pruning 的，核心想法是：将某个 weight 的值设置为 0，同时调整其他位置的权重，使总体上对 loss 的影响最小。</p>
<p>对 loss function 的微分进行泰勒展开，充分训练下没有一阶导项，忽略高阶微分项，最终得到 delta loss function 的表达式。</p>
<p><img alt="Tayler Expansion of Loss Function" src="../SurveyOnQuantization.assets/obs_tayler.png" width="75%" /></p>
<p>然后在 pruning 约束条件下对目标函数进行拉格朗日乘数法求解，最终得到两个关键表达式。</p>
<p><img alt="Two Key Expressions" src="../SurveyOnQuantization.assets/obs_key_equations.png" width="50%" /></p>
<ol>
<li>对其他权重的变化量 <span class="arithmatex">\(\delta_{\mathbf{W}}\)</span>（最后两个因子可以简化为 <span class="arithmatex">\(H^{-1}\)</span> 的第 q 列）</li>
<li>优化 q 对整个 loss 引起的变化 <span class="arithmatex">\(L_q\)</span> ，这个可以用来找到最佳的 q</li>
</ol>
<h4 id="obc-obq">OBC &amp; OBQ</h4>
<p>OBC 在 OBS 的基础上假设 Hessian 矩阵的每一行相对独立（基于参数独立假设），并提出了对 Hessian 的迭代更新算法，避免频繁对 Hessian 矩阵求逆。</p>
<p><img alt="Hessian Updating" src="../SurveyOnQuantization.assets/obc_hessian_update.png" width="50%" /></p>
<p>而 OBQ 将 pruning 视为一种特殊的 quantization，从而将 OBC 改造为 quantization 算法。
<img alt="Two Key Expressions in OBQ" src="../SurveyOnQuantization.assets/obq_key_equations.png" /></p>
<p>整个量化过程是：</p>
<ol>
<li>针对每一行，找到对 loss 影响最小的权重，对其进行量化</li>
<li>计算 <span class="arithmatex">\(\delta_p\)</span>，更新其他权重</li>
<li>更新 Hessian 矩阵</li>
<li>重复 1-3 步，直至完成该行的更新</li>
<li>每一行的更新是独立的，可以并行</li>
</ol>
<p>在量化时还有一个 trick，对于量化中的 outliers，他们在量化前后会造成较大的 error，在贪心算法中会让他们最后才被 quantized，
而这样最后还未量化的权重数量很少，难以通过调整其他权重减小 loss。因此需要让 outliers 尽早被 quantize。</p>
<h3 id="gptq">GPTQ 的核心想法</h3>
<details class="quote">
<summary>Quote</summary>
<ul>
<li>E. Frantar, S. Ashkboos, T. Hoefler, and D. Alistarh, “GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers,” Mar. 22, 2023, arXiv: arXiv:2210.17323. doi: 10.48550/arXiv.2210.17323.</li>
</ul>
</details>
<p>在 OBQ 的基础上改进，主要有以下三点：</p>
<ol>
<li>将基于 delta loss 的贪心算法改成顺序的算法，因为顺序在大模型下基本不影响量化效果。这样就可以以同样的顺序量化每一行</li>
<li>
<p>Lazy Batch Update：OBQ 中每 quantize 一个参数就要更新所有的参数，
    而在 GPTQ 中，他将 columns 分成若干组 block，分成 local update 和 global update。</p>
<p>local update 是在 block 内部，将前面量化参数的影响更新到 block 内的后续参数中；</p>
<p>global update 则是在一个 block 更新完后，利用矩阵运算对后续所有参数进行批量更新。</p>
<p>这样 local update 的计算量较小，而计算量较大的 global update 又可以通过 batched update 的方式充分利用计算资源。</p>
</li>
<li>
<p>利用 Cholesky 分解预计算 <span class="arithmatex">\(H^{-1}\)</span> 。由于量化的顺序已经确定，所以可以直接预计算 <span class="arithmatex">\(H^{-1}\)</span> 。这个预计算的过程和 Cholesky 分解等价。</p>
</li>
</ol>
<p><strong>所以最核心的 idea 就是第一条的 insight，即 order does not matter。</strong> 量化顺序的 in order 带来了 update in batch，带来了 precompute <span class="arithmatex">\(H^{-1}\)</span> 。</p>
<h3 id="gptq_1">GPTQ 代码实现</h3>
<details class="note">
<summary>核心代码</summary>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">damp</span> <span class="o">=</span> <span class="n">percdamp</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">H</span><span class="p">))</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">diag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dev</span><span class="p">)</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">H</span><span class="p">[</span><span class="n">diag</span><span class="p">,</span> <span class="n">diag</span><span class="p">]</span> <span class="o">+=</span> <span class="n">damp</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cholesky_inverse</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="n">Hinv</span> <span class="o">=</span> <span class="n">H</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="k">for</span> <span class="n">i1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">blocksize</span><span class="p">):</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span class="n">i2</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i1</span> <span class="o">+</span> <span class="n">blocksize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">count</span> <span class="o">=</span> <span class="n">i2</span> <span class="o">-</span> <span class="n">i1</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">W1</span> <span class="o">=</span> <span class="n">W</span><span class="p">[:,</span> <span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">Q1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W1</span><span class="p">)</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="n">Err1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W1</span><span class="p">)</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">Losses1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">W1</span><span class="p">)</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">Hinv1</span> <span class="o">=</span> <span class="n">Hinv</span><span class="p">[</span><span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">,</span> <span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">]</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">):</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>        <span class="n">w</span> <span class="o">=</span> <span class="n">W1</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        <span class="n">d</span> <span class="o">=</span> <span class="n">Hinv1</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>        <span class="k">if</span> <span class="n">groupsize</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">static_groups</span><span class="p">:</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>                <span class="k">if</span> <span class="p">(</span><span class="n">i1</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="n">groupsize</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">find_params</span><span class="p">(</span><span class="n">W</span><span class="p">[:,</span> <span class="p">(</span><span class="n">i1</span> <span class="o">+</span> <span class="n">i</span><span class="p">):(</span><span class="n">i1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="n">groupsize</span><span class="p">)],</span> <span class="n">weight</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>                <span class="n">idx</span> <span class="o">=</span> <span class="n">i1</span> <span class="o">+</span> <span class="n">i</span>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>                <span class="k">if</span> <span class="n">actorder</span><span class="p">:</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>                    <span class="n">idx</span> <span class="o">=</span> <span class="n">perm</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">quantizer</span> <span class="o">=</span> <span class="n">groups</span><span class="p">[</span><span class="n">idx</span> <span class="o">//</span> <span class="n">groupsize</span><span class="p">]</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>        <span class="n">q</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>            <span class="n">w</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">zero</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantizer</span><span class="o">.</span><span class="n">maxq</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>        <span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        <span class="n">Q1</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="n">Losses1</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">d</span> <span class="o">**</span> <span class="mi">2</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="n">err1</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span> <span class="o">/</span> <span class="n">d</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="n">W1</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:]</span> <span class="o">-=</span> <span class="n">err1</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Hinv1</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>        <span class="n">Err1</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">err1</span>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>    <span class="n">Q</span><span class="p">[:,</span> <span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q1</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>    <span class="n">Losses</span><span class="p">[:,</span> <span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">]</span> <span class="o">=</span> <span class="n">Losses1</span> <span class="o">/</span> <span class="mi">2</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>    <span class="n">W</span><span class="p">[:,</span> <span class="n">i2</span><span class="p">:]</span> <span class="o">-=</span> <span class="n">Err1</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Hinv</span><span class="p">[</span><span class="n">i1</span><span class="p">:</span><span class="n">i2</span><span class="p">,</span> <span class="n">i2</span><span class="p">:])</span>
</span></code></pre></div>
</details>
<p>相比于 OBQ 的代码，不需要再进行 Hessian 矩阵的更新，而是直接使用 Cholesky 分解对 Hessian 进行预计算。
同时通过两层循环实现了对权重的 local update 和 global update。</p>
<h3 id="gptq_2">对 GPTQ 的一些思考</h3>
<p>GPTQ 虽然非常有效，但主要还是基于 Hessian 矩阵的调整，而 Hessian 矩阵是通过 <span class="arithmatex">\(H=2X^TX\)</span> 近似得到的，从而不可避免地存在偏差。</p>
<p>GPTQ 最重要的思想还是在 OBS 中提出的通过 Tayler Expansion 转换成一个优化问题，通过调整其他参数来使整体 loss 最小的一个思路。这个思路可以用到很多地方，值得注意。</p>
<h2 id="awq">AWQ</h2>
<details class="quote">
<summary>Quote</summary>
<ul>
<li>J. Lin et al., “AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration,” Proceedings of Machine Learning and Systems, vol. 6, pp. 87–100, May 2024.</li>
</ul>
</details>
<h3 id="awq_1">AWQ 的核心想法</h3>
<p>AWQ 基于一个 observation: 保留 1% salient weights 不被量化可以显著提升量化后模型的 performance。</p>
<p>接下来问题是如何判断 salience：AWQ 基于 magnitude of activation 来判断 salience，而不是 weights。
这是很合理的。因为我们要判断 weights 的 salience，那么当 magnitude of activation 越大，对应 weight 的微小变化对 output 的影响就越大。</p>
<p>在此基础上，AWQ 想要进一步量化 salient weights：利用 Activation-aware Scaling 来减小 salient weight 量化后的 error。</p>
<p><img alt="Activation-aware Scaling" src="../SurveyOnQuantization.assets/awq_scaling.png" width="70%" /></p>
<p>可以看到，当对 weight 和 input 分别施加相反的 scaling factor，最终的 error 会随着 s 的增大而减小。这便是 AWQ 的核心机制。</p>
<p>需要注意的是，这里有一个核心假设：“Scaling up a single element w usually does not change the maximum value from the group w. Therefore we have ∆′ ≈ ∆”
有了这个假设的存在，才能够保证额外的 scaling 是生效的。否则的话 scaling 越大 ∆′ 也会越来越大，从而导致误差越来越大。</p>
<p>这也是 scaling salient weight only 的原因，因为如果 scaling 所有 weight，这个假设便不再成立，从而使 error 越来越大。</p>
<p>最终实际上 AWQ 对每一个 input channel 都计算一个 scaling factor，scaling factor 基于 magnitude of activation 来决定。</p>
<p>scaling factor vector <span class="arithmatex">\(\mathbf{s} = \mathbf{s}_{\mathbf{x}} ^ \alpha\)</span>，通过 grid search 找到最佳 <span class="arithmatex">\(\alpha\)</span></p>
<h3 id="awq_2">AWQ 代码实现</h3>
<p>我跑了一下 AWQ 的 examples，发现 AWQ 实现了 W4A4 的量化，设计了基于 INT4 的 customed CUDA kernel 来进行推理。</p>
<p>所以 AWQ 的量化过程包括以下几个部分：</p>
<ol>
<li>使用论文中提到的方法对权重进行量化</li>
<li>将量化后的 INT4 权重 pack 存储到 INT32 中。</li>
<li>将模型原有的 Linear 层替换为 QLinear 层，其中调用 customed kernel 进行 INT4 Inference</li>
</ol>
<p>由此，AWQ 能够在计算和访存上都减少开销。</p>
<h3 id="awq_3">对 AWQ 的一些思考</h3>
<p>AWQ 中有一些思路可以进行学习：</p>
<ol>
<li>weight salience 应该考虑 activation 而不是 weight 本身。因为当 magnitude of activation 越大，对应 weight 的微小变化对 output 的影响就越大。</li>
<li>这个 scaling 看起来非常 tricky，不知道背后有没有一些更深层次的想法，后续可以留意一下。</li>
</ol>
<h2 id="qlora">QLoRA</h2>
<details class="quote">
<summary>Quote</summary>
<ul>
<li>E. J. Hu et al., “LoRA: Low-Rank Adaptation of Large Language Models,” Oct. 16, 2021, arXiv: arXiv:2106.09685. doi: 10.48550/arXiv.2106.09685.</li>
<li>T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, “QLoRA: Efficient Finetuning of Quantized LLMs,” Advances in Neural Information Processing Systems, vol. 36, pp. 10088–10115, Dec. 2023.</li>
</ul>
</details>
<h3 id="lora-low-rank-fine-tuning">LoRA: low-rank fine-tuning</h3>
<p>通过在权重上加上一对低秩矩阵乘来对权重进行微调。</p>
<p>核心：<span class="arithmatex">\(W' = W + AB\)</span></p>
<p><img alt="LoRA" src="../SurveyOnQuantization.assets/lora.png" width="50%" /></p>
<p>当 <span class="arithmatex">\(r &lt;&lt; d\)</span> 时，finetuning 时需要的参数就大大减小。</p>
<h3 id="qlora_1">QLoRA 的核心想法</h3>
<p>QLoRA 的目的是为了通过量化优化 LoRA 过程，但是其中的一些量化思想还是可以学习的。同时 QLoRA/LoRA 现在还是主流的 fine-tune 方法。</p>
<p>关于 QAT/PTQ：QLoRA 虽然是用于微调（训练）环节，但是其量化的是原权重，而在 LoRA 中原权重不需要被更新，因此其中的思路还是偏 PTQ 一些</p>
<p>QLoRA 主要两个核心思路</p>
<p>一是提出 NF4，基于 weights 大多遵循 normal distribution 的 insight，因此权重在每一个量化值的概率分布不是均匀的，自然量化值的分布也不应该是均匀的。
在概率越大的地方量化值分布应该更集中以获得更高的精度，而在概率小的地方量化值分布应该更稀疏。</p>
<p>二是提出双量化（可以看作是一种 2-level quantization），level-1 是用 small group size 对参数进行量化。由于 group size 较小，会产生许多 additional parameters for each group。
然后 level-2 对 group in level 1 再进行一个分组，对 additional parameters 再进行量化。这样既有 small group size 对精度的优势，
又避免了 small group size 带来更多 additional parameters 造成的显存占用问题。</p>
<h3 id="qlora_2">对 QLoRA 的一些思考</h3>
<ul>
<li>我觉得 NF4 这个数据类型的思考挺合理的，但是并没有成为主流，是否因为目前硬件并不支持 NF4 的运算呢？如果是这样的话，那为什么 QLoRA 还要坚持使用 NF4 呢？可以做一些实验试试，NF4 在 finetuning 这个场景下有什么特别的作用吗？</li>
<li>QLoRA 这个 double quantization 可以留意一下。他和 multi-level quantization 不一样。double quantization 是对第一次量化的量化参数再进行量化，而 multi-level quantization 则是在不同 level 采用不同的量化粒度和不同的量化参数精度。
    个人认为 multi-level quantization 更合理一些，double quantization 更像只是为了提高压缩率的一个 trick，不过不失为一种在细粒度量化下改善压缩率的方法。</li>
</ul>
<h2 id="qllm">QLLM</h2>
<details class="quote">
<summary>Quote</summary>
<ul>
<li>J. Liu, R. Gong, X. Wei, Z. Dong, J. Cai, and B. Zhuang, “QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models,” Apr. 06, 2024, arXiv: arXiv:2310.08041. doi: 10.48550/arXiv.2310.08041.</li>
</ul>
</details>
<h3 id="qllm_1">QLLM 的核心想法</h3>
<p>核心思想是在不同 channels 之间进行 reassembly</p>
<div class="arithmatex">\[\mathbf{y} = \sum \mathbf{x}_i \mathbf{W}_{i, :}\]</div>
<p>这个 summation 中的每一项为一个 channel 的计算结果，核心思想是保证最终结果 summation 不变的前提下，在不同 channels 之间分配，进行 reassembly，从而减小 outliers 对 quantization 的影响。</p>
<p>Reassembly 主要分为 disassembly 和 assembly 两步。</p>
<ul>
<li>Disassembly 将一个 channel 拆分成多个 sub-channels，从而将权重值限定在 threshold 之内</li>
<li>
<p>Assembly 将多个相似 channels 的权重进行加总合并，从而实现对 channels 的合并</p>
<p>这个有一个问题就是在对权重进行 reassembly 的同时，也需要对输入 <span class="arithmatex">\(\mathbf{x}\)</span> 进行 reassembly，这会引来一定的开销，并且是 memory-access intensive 的。</p>
</li>
<li>
<p>Disassembly 需要对 <span class="arithmatex">\(\mathbf{x}\)</span> 的对应 channels 进行拆分（实现上是 scaling + repeating）</p>
</li>
<li>Assembly 需要对 <span class="arithmatex">\(\mathbf{x}\)</span> 对应的 channels 求均值</li>
</ul>
<h3 id="qllm_2">对 QLLM 的一些思考</h3>
<ul>
<li>在不同 channels 之间进行权重的重新分配从而缓解 outlier 的问题，我觉得这个想法是非常好的。从 <span class="arithmatex">\(\mathbf{y} = \sum \mathbf{x}_i \mathbf{W}_{i, :}\)</span>
    出发，保持 summation 不变的情况下在不同 terms 之间进行分配，这个思路非常有意义。</li>
<li>但是这样引入的额外计算我觉得有点不够优雅，能否有一个能够在不同 channels 之间分配，而又能够更好地减少 overhead 的方法呢？</li>
</ul>
<h2 id="zipcache">ZipCache</h2>
<details class="quote">
<summary>Quote</summary>
<ul>
<li>Y. He, L. Zhang, W. Wu, J. Liu, H. Zhou, and B. Zhuang, “ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification,” May 23, 2024, arXiv: arXiv:2405.14256. doi: 10.48550/arXiv.2405.14256.</li>
</ul>
</details>
<h3 id="zipcache_1">ZipCache 的核心想法</h3>
<p>第一个是在 KV Cache 压缩时通常从 token-wise 压缩，然而 outlier 的分布是在 channel 维度上的，这样就会使每一个 token 的压缩都会受到 outlier 的严重影响。<br />
为此，ZipCache 提出在 channel-wise 上做一个 normalization，使 channels 之间的 magnitude 在同一 level，从而显著减小 outlier 的影响。</p>
<p><img alt="Channel-separable Tokenwise Quantization" src="../SurveyOnQuantization.assets/zipcache_channel_separated.png" /></p>
<p>第二个是在 KV Cache Compression 中判断 salient tokens 时，主流工作用的都是 accumulated attention score 作为 metrics，但这个标准会存在问题，没有考虑到每个 accumulated score 的 summation terms 数量不同，同时会受到 softmax 的归一化影响，所以是不合理的<br />
为此，ZipCache 提出 normalized attention score，即在非零元素之间求 mean</p>
<p><img alt="Normalized Attention Score" src="../SurveyOnQuantization.assets/zipcache_normalized_attention_score.png" width="50%" /></p>
<p>同时还指出在计算 Salience 的时候需要计算整个 attention score matrix，这与 flash attention 不兼容。为此 ZipCache 提出对 tokens 进行 samples，以部分 tokens 对整个序列其他 tokens 的 attention scores 来进行近似。</p>
<h3 id="zipcache_2">对 ZipCache 的一些思考</h3>
<ul>
<li>ZipCache 和上面一些工作的不同之处是，ZipCache 专注于对 KV Cache 的量化，而上面的工作都是专注于对 Linear weight 的量化。从这里可以看到 KV Cache Compression 具有自己的特点，可以带来一些和 weight quantization 不一样的思路和创新点。</li>
<li>个人很喜欢 ZipCache 提出的两个想法，这两个 idea 都是基于前人工作的基础上，基于 KV Cache Compression 的某些特点去进行改进。整个思路我觉得非常清晰且自然。</li>
<li>在兼容 Flash Attention 时提出的 sampling 的思路我觉得也具有一定的普适性，虽然在理论上缺少一定的支撑，但是在工程上具有一定的实践意义，后续可以留意一下。</li>
</ul>
<h2 id="_5">下一步工作</h2>
<ul>
<li>本文基本介绍的都是 PTQ 相关技术，可以进一步研究 QAT。</li>
<li>本文只选取了一些在各个应用的代表性工作，后续可以在某一个方向上做更详细的调研</li>
<li>本文很大篇幅都在介绍 weight quantization，对 KV cache compression 介绍较少，可以进一步进行专题研究。</li>
</ul>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="June 29, 2025 07:38:31 UTC">June 29, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="June 29, 2025 07:38:31 UTC">June 29, 2025</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>